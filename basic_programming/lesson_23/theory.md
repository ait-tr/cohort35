## 01. Как оценивать алгоритмы?

* Надо понимать, что лучше, а что хуже
* Можно оценивать память, можно оценивать скорость.
* Интереснее скорость, а не память
* Теперь, когда мы будем говорить, что один алгоритм лучше другого - мы имеем в виду, что один быстрее другого
* В чем измерять?
  * `Фактическое время` работы (в секундах, минутах и т.д.) -  На фиксированном наборе данных
    * Потому что алгоритм может быть запущен на разном железе и на разном железе он будет давать разные результаты
    * А если данные все-таки захотим менять? Получается оценка будет очень плавающей.
  * `Количество операций`, которые выполняет алгоритм (сравнение, сложение, запись/чтение, умножение, деление и т.д.)
    * Например, алгоритм A выполнил на наборе данных X 100 действий, а B - 50, значит B - лучше
    * В этом случае мы говорим так - что алгоритм B лучше, потому что требует меньше операций, т.е. меньше времени
    * Плюс такого подхода - независимость от железа
    * На любом железе один и тот же алгоритм будет выполнять одно и то же количество операций
    * В чем минус такого подхода? В том, что алгоритм A на наборе данных Y может дать 100 операций, а на набор данных Z - 5000 операций
    * Что это означает? Что алгоритмы очень сильно зависят от тех данных, которые им подали.
    * Мы не можем сказать, что алгоритм требует всегда 100 операций, это сильно зависит от того, что мы подали на вход.
  * `Функция от количества входных данных` - описать функцию, которая на количестве данных будет давать вам ответ - сколько операций

## 02. Вспоминаем математику

* Функция в математике - это зависимость одной величины от другой. Как правило, записывается `y = f(x)`
* Здесь `x` - параметр функции, `y` значение функции в точке `x`
* Например, есть функция `парабола`, `y = x^2` (т.е. `y = x * x`), она принимает в точках следующие значения:
  * `x = 0`, `y = 0`
  * `x = 1`, `y = 1`
  * `x = 2`, `y = 4`
  * `x = 3`, `y = 9`
  * `x = 4`, `y = 16`
  * `x = -1`, `y = 1`
  * `x = -2`, `y = 4`
  * `x = -3`, `y = 9`
  * и т.д.
* Наш же интересуют функции, которые определены только на целых положительных числах
* Это означает, что в нашем случае - `x` - это размер входных данных (т.е. их количество)
* А `y` - это количество операций, которые нужны для обработки алгоритмом этого набора данных
* Для нас скорость алгоритма теперь будет оцениваться какой-либо функцией, и наша задача - научиться их отличать друг от друга
* По виду функции понять, что лучше, а что хуже.

## 03. Рассмотрим алгоритм обмена максимума и минимума в массиве

* Надо найти минимум - 

```
        // 1
        int min = array[0];
        // 1
        int minIndex = 0;
        // ИТОГО 2
        
        for (int i = 1; i < array.length; i++) {
            // В самом for три операции - 3
            
            // 1
            if (min > array[i]) {
                // 1
                min = array[i];
                // 1
                minIndex = i;
            }
            // ИТОГО: 6
        } // повторяем array.length - 1 раз эти 6 операций
```

* Пусть array.length = N, тогда поиск минимума - `2 + N * 6` операций
* Надо найти максимум - `2 + N * 6` операций
* Надо их поменять местами - `3` операции
* Итого: `2 + 6N` + `2 + 6N` + `3` = `12 * N + 7`
* Скорость нашего алгоритма, это функция y = f(N) = `12N + 7`
* Т.е. если ваш массив будет иметь размер `1250`, то потребуется `15 007` операций
* Мы можем улучшить наш алгоритм так, чтобы он использовал один цикл вместо двух
  * Итого: `6N + 7`
* Мы с вами понимаем, что алгоритмы можно измерять с помощью функций.
* По графикам, которые мы рассмотрели, можно сделать вывод, что при увеличении количества данных обе функции растут "пропорционально"
* Это просто прямые линии, пусть и с разным наклоном
* С этой точки зрения, мы можем сказать, что оба алгоритма работают одинаково и они - линейные.
* При увеличении количества данных - оба алгоритма замедляются "линейно" (пропорционально).
* Оба алгоритма имеют "асимптотическую сложность" - O(N) (линейная сложность).
* Функция таких алгоритмов очень похожа на `y = x`
* Алгоритмы бесполезно улучшать методом "уменьшения количества операций", они все равно будут считаться одинаковыми по скорости работы.
* Потому что они будут принадлежать одному семейству, например "линейных алгоритмов"

## 04. Рассмотрим линейный поиск

```
public static int linearSearch(int[] array, int value) {

        for (int i = 0; i < array.length; i++) {
            if (array[i] == value) return i;
        }

        return -1;
    }
```

* Какая у него "сложность" (скорость работы алгоритма в терминах "количество операций") = `4 * N`
* Асимптотическая сложность - O(N)

### Что за O(N)

* `x ~ N`
* `O(N)` - асимптотика функции
* Мы говорим, что `y = 4N`, `y = 6N + 7` асимптотически равны функции y = N
* Асимптотически равны - растут так же, как и `y = N`
* Мы можем сказать, что любая функция вида `y = kx + m` ~ `y = x`

## 05. Рассмотрим случай бинарного поиска

* Старт алгоритма - `4 операции`
* Цикл
  * `counter` - `1 операция`
  * `вычисление середины` - `4 операции`
  * `сравнение с серединой` - `1 операция`
  * `переход либо к левой части, либо к правой` - `2 операции`
* Итого в цикле одна итерация ~ `8 операций`
* Вопрос, а сколько всего итераций происходит?

* Попробуем посчитать на конкретном примере:

```
Пусть длина массива N = 128 (всего в массиве 128 элементов)
Считаем, что искомого элемента в массиве нет (худший случай)

1. Получим середину, посмотрим на нее, сделаем вывод, вправо или влево (отсекаем 64 элемента, половину, остается 64)
2. Получим середину, посмотрим на нее, сделаем вывод, вправо или влево (отсекаем 3элемента, половину, остается 32)
3. Получим середину, посмотрим на нее, сделаем вывод, вправо или влево (отсекаем 2 16 элементов, половину, остается 16)
4. Получим середину, посмотрим на нее, сделаем вывод, вправо или влево (отсекаем 8 элементов, половину, остается 8)
5. Получим середину, посмотрим на нее, сделаем вывод, вправо или влево (отсекаем 4 элементов, половину, остается 4)
6. Получим середину, посмотрим на нее, сделаем вывод, вправо или влево (отсекаем 2 элементов, половину, остается 2)
7. Получим середину, посмотрим на нее, сделаем вывод, вправо или влево (отсекаем 1 элементов, половину, остается 1)
```

* Т.е. для массива длины `128` мы получили `7` итераций в цикле.
* А что такое `7` относительно `128`
* Если мы возьмем число `2` и возведем в степень `7` = `2 * 2 * 2 * 2 * 2 * 2 * 2` = `128`
* `2^7 = 128`, т.е. `7` - это степень, в которую нужно возвести `2` чтобы получить `128`
* `7` - это логарифм числа `128` по основанию `2`
* `7` = `log2(128)`
* Следовательно, цикл для массива длины `N` выполнится `log2(N)` раз
* Следовательно, сложность бинарного поиска `8 * log2(N)`
* На какой график это похоже? - на график `log2(N)`
* Мы можем сказать, что бинарный поиск гораздо медленнее растет, в отличие от линейного поиска.
* График логарифма очень "пологий"
* Поэтому бинарный поиск - самый лучший способ искать данные
* Говорят, что бинарный поиск имеет `логарифмическую сложность` и обозначается - `O(log(N))`
* При увеличении данных у логарифмических алгоритмов медленнее падает скорость работы

## 06. Рассмотрим алгоритм сортировки выбором

* Немного упростим жизнь:
  * Цикл по `i` выполняется `N-раз`
    * Но цикл по `j` находится внутри этого цикла, и выполняется какое-то количество раз, но какое?

```
Пусть есть массив из 10 элементов

Тогда:
i = 0, j -> выполнится от 1 до 9 -> 9 раз
i = 1, j -> выполнится от 2 до 9 -> 8 раз
i = 2, j -> выполнится от 3 до 9 -> 7 раз
i = 3, j -> выполнится от 4 до 9 -> 6 раз
i = 4, j -> выполнится от 5 до 9 -> 5 раз
i = 5, j -> выполнится от 6 до 9 -> 4 раз
i = 6, j -> выполнится от 7 до 9 -> 3 раз
i = 7, j -> выполнится от 8 до 9 -> 2 раз
i = 8, j -> выполнится от 9 до 9 -> 1 раз
i = 9, j ->  -> 0 раз

ИТОГО: 0 + 1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 = 45 раз
```

Как относится между собой число 10 (количество входных элементов) и число 45 (сколько операций потребовалось)?

* Если у вас N элементов, то количество операций равно: `1 + 2 + 3 + ... + N-1` операций
* Как это изобразить в виде формулы? А это вас просто сумма членов арифметической прогрессии
* Формула этой суммы - `(2 * 1 + 1 * (N - 1) / 2) * N = (2 + (N - 1) / 2) * N = ((N + 1) / 2) * N` =
* `1/2 * (N+1) * N` = `1/2 * (N^2 + N)`
* Мы с вами говорим, что сортировка выбором имеет `квадратичную сложность`, то есть скорость работы алгоритма замедляется в квадрат раз от входных данных
* Эта функция растет быстрее всего
* Ее асимптотика обозначается как `O(N^2)`
* Кстати, у пузырьковой сортировки сложность тоже `O(N^2)`

## Другие виды сложностей

* Для сортировок оптимальной является `O(nlog(n)` - это скорость, которая характерна для:
  * Сортировка слиянием (Merge Sort)
  * Быстрая сортировка (Quick Sort)
  * Обе эти сортировки есть в Java

## 07. O-нотация

* Почему O-нотация и что она обозначает с точки зрения математики?
* O-нотация позволяет записать функцию, которая имеет такое же поведение, как какая-либо другая функция:
  * Функция `y = 5x + 7` имеет такое же поведение, как и `y = x`, поэтому говорят, что `O(x) ~ 5x + 7`
  * Функция `y = 5x^2 + 10` имеет такое же поведение, как и `y = x^2`, поэтому говорят `O(x^2) ~ 5x^2 + 10`
* В анализе скорости работы алгоритмов нас не интересуют конкретные числа, нас интересует порядок роста функции (поведение)

## Небольшие комментарии по реальной разработке

* На практике, чем кто-кроме `sort` и `contains`:

```
        list.stream().sorted();
        list.contains(10);
```

* Что реально нужно знать, чтобы программировать на java?
  * ООП в Java (классы, объекты, абстрактные классы, интерфейсы, наследование, полиморфизм, вложенные классы и т.д.)
  * Java Collection Framework (List, ArrayList, Map)
  * Stream API
  * Threads (очень опционально)

* Что нужно знать сверху (Backend)
  * JDBC
  * Spring (+ Spring Web, + Spring Security)
  * Spring Boot
  * Liquibase

### Тезисы

* Что нужно знать?
  * Функция в математике
  * Степень
  * Логарифм
  * График функции
  * Арифметическая прогрессия
* Алгоритмы, как правило, сравниваются между собой O-нотацией
* Такая нотация показывает, насколько быстро растет время работы (количество операций) алгоритма в зависимости от входных данных
  * `O(1)` - константное время работы, не зависит от входных данных
  * `O(log(N))` - время работы растет очень медленно при увеличении входных данных
  * `O(N)` - растет пропорционально входным данным
  * `O(NlogN)` - растет быстрее, чем линейная, но медленнее, чем квадратичная
  * `O(N^2)` - время растет квадратично при увеличении входных данных (очень быстро)
  * `O(1)` < `O(log(N))` < `O(N)` < `O(NlogN)` < `O(N^2)`
* Вам не нужно уметь вычислять скорость работы произвольных алгоритмов, нужно просто понимать, что эти обозначения показывают
* Как по коду понять, хороший алгоритм или нет?
* Универсального рецепта нет, но:
  * Если два вложенных цикла - скорее всего `O(N^2)`, либо `O(NlogN)`
  * Если один цикл от `0 до N` - скорее всего `O(N)`
  * Вывод - вложенные циклы всегда хуже, чем что-то другое.

![Complexity](https://raw.githubusercontent.com/ait-tr/cohort35/main/basic_programming/lesson_23/img/1.png)